import streamlit as st
import os
import tempfile
import nest_asyncio
import logging
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings, PromptTemplate
from llama_index.llms.groq import Groq
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

# --- LOGGING CL√çNICO ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger("MediSync_Log")

# 1. Configura√ß√£o
nest_asyncio.apply()
st.set_page_config(page_title="MediSync AI - Sa√∫de Integrada", page_icon="üè•", layout="wide")

# --- VISUAL "CLINICAL CLEAN" (CSS Hospitalar) ---
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Lato:wght@400;700&family=Roboto:wght@400;500&display=swap');
    
    /* Ambiente Est√©ril/Clean */
    .stApp { background-color: #f8f9fa; font-family: 'Lato', sans-serif; }
    
    /* Cabe√ßalhos */
    h1, h2, h3 { font-family: 'Roboto', sans-serif !important; color: #2d3436 !important; font-weight: 700 !important; }
    
    /* Sidebar */
    [data-testid="stSidebar"] { background-color: #ffffff; border-right: 1px solid #e1e4e8; }
    
    /* Bot√µes (Verde Sa√∫de) */
    .stButton > button {
        background-color: #00b894; color: white !important; border: none;
        border-radius: 25px; padding: 0.6rem 1.2rem; font-weight: 600;
        box-shadow: 0 2px 5px rgba(0, 184, 148, 0.2); width: 100%;
    }
    .stButton > button:hover { background-color: #00a884; transform: translateY(-1px); }

    /* Chat (Bal√µes) */
    [data-testid="stChatMessage"] { background-color: #ffffff; border: 1px solid #dfe6e9; border-radius: 15px; }
    
    /* Avatar da IA */
    [data-testid="stChatMessage"] [data-testid="stImage"] { background-color: #e3fdfd; border: 2px solid #00b894; }
</style>
""", unsafe_allow_html=True)

# 3. Autentica√ß√£o
api_key = st.secrets.get("GROQ_API_KEY") or os.environ.get("GROQ_API_KEY")
if not api_key:
    st.error("‚ö†Ô∏è SISTEMA OFF-LINE: Configure a chave API nos Secrets.")
    st.stop()
os.environ["GROQ_API_KEY"] = api_key

# 4. Protocolos de IA (Prompts)
PROMPT_PROFISSIONAL = (
    "ATUE COMO: Especialista Cl√≠nico Multidisciplinar (Enfermagem/Medicina/Psicologia).\n"
    "CONTEXTO: An√°lise de prontu√°rios, artigos cient√≠ficos e exames.\n"
    "DIRETRIZES:\n"
    "1. Use terminologia t√©cnica padr√£o (CID-10, DSM-5, NANDA, Terminologia Cir√∫rgica).\n"
    "2. Seja direto, focado em diagn√≥stico diferencial, farmacologia e conduta cl√≠nica.\n"
    "3. Cite valores de refer√™ncia e evid√™ncias cient√≠ficas encontradas no texto.\n"
    "---------------------\n"
    "DADOS CL√çNICOS: {context_str}\n"
    "QUERY PROFISSIONAL: {query_str}\n"
    "PARECER T√âCNICO:"
)

PROMPT_PACIENTE = (
    "ATUE COMO: Um Profissional de Sa√∫de Humanizado e Emp√°tico.\n"
    "OBJETIVO: Explicar sa√∫de de forma simples, sem causar p√¢nico.\n"
    "DIRETRIZES:\n"
    "1. Traduza termos t√©cnicos para linguagem do dia a dia.\n"
    "2. Foque no cuidado, preven√ß√£o e bem-estar.\n"
    "3. Seja acolhedor. Se algo for grave, oriente buscar ajuda presencial com calma.\n"
    "4. Use listas ou t√≥picos para facilitar a leitura.\n"
    "---------------------\n"
    "INFORMA√á√ïES: {context_str}\n"
    "PERGUNTA DO PACIENTE: {query_str}\n"
    "RESPOSTA ACOLHEDORA:"
)

# 5. Carregar Motor
@st.cache_resource
def carregar_sistema():
    Settings.llm = Groq(model="llama-3.3-70b-versatile")
    Settings.embed_model = HuggingFaceEmbedding(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    return True

carregar_sistema()

# 6. Sidebar
with st.sidebar:
    st.title("üè• MediSync AI")
    st.caption("Intelig√™ncia Cl√≠nica Avan√ßada")
    st.markdown("---")
    
    perfil = st.radio(
        "MODO DE OPERA√á√ÉO:",
        ["PROFISSIONAL DE SA√öDE", "PACIENTE / FAMILIAR"],
        index=0
    )
    
    st.info("Formatos aceitos: Prontu√°rios, Exames (PDF/TXT), Bulas, Artigos.")
    uploaded_files = st.file_uploader("Arquivo M√©dico", accept_multiple_files=True)
    
    if uploaded_files and st.button("ANALISAR DADOS"):
        with st.spinner("Processando dados vitais..."):
            try:
                with tempfile.TemporaryDirectory() as temp_dir:
                    for uploaded_file in uploaded_files:
                        path = os.path.join(temp_dir, uploaded_file.name)
                        with open(path, "wb") as f:
                            f.write(uploaded_file.getbuffer())
                    
                    documents = SimpleDirectoryReader(temp_dir).load_data()
                    st.session_state.index = VectorStoreIndex.from_documents(documents)
                    st.session_state.loaded = True
                    logger.info(f"UPLOAD: {len(uploaded_files)} docs m√©dicos.")
                st.success("‚úÖ Prontu√°rio Indexado.")
            except Exception as e:
                st.error(f"Erro: {e}")

# 7. Chat
if "messages" not in st.session_state: st.session_state.messages = []

st.title("Prontu√°rio Inteligente")

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]): st.markdown(msg["content"])

if prompt := st.chat_input("Digite a d√∫vida cl√≠nica ou queixa..."):
    if not st.session_state.get("loaded"):
        st.warning("‚ö†Ô∏è Por favor, anexe o caso cl√≠nico na barra lateral.")
        st.stop()

    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"): st.markdown(prompt)
    
    with st.chat_message("assistant"):
        with st.spinner("Analisando evid√™ncias..."):
            try:
                template = PromptTemplate(PROMPT_PROFISSIONAL if perfil == "PROFISSIONAL DE SA√öDE" else PROMPT_PACIENTE)
                engine = st.session_state.index.as_query_engine(text_qa_template=template, similarity_top_k=5)
                
                response = engine.query(prompt)
                st.markdown(str(response))
                st.session_state.messages.append({"role": "assistant", "content": str(response)})
                logger.info(f"CONSULTA [{perfil}]: Respondida.")
            except Exception as e:
                st.error("Erro na an√°lise cl√≠nica.")