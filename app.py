import streamlit as st
import os
import tempfile
import nest_asyncio
import logging
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings, PromptTemplate
from llama_index.llms.groq import Groq
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

# --- LOGGING (Monitoramento de Pacientes/Usu√°rios) ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger("MediSync_Tracker")

# 1. Configura√ß√£o do Sistema
nest_asyncio.apply()

st.set_page_config(
    page_title="MediSync AI - Intelig√™ncia Cl√≠nica",
    page_icon="üè•",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- VISUAL "CLINICAL CLEAN" (CSS) ---
st.markdown("""
<style>
    /* Fonte Limpa e Moderna (Roboto/Lato) */
    @import url('https://fonts.googleapis.com/css2?family=Lato:wght@400;700&family=Roboto:wght@400;500&display=swap');

    /* Fundo Geral Clean */
    .stApp {
        background-color: #f4f7f6;
        font-family: 'Lato', sans-serif;
    }

    /* Barra Lateral (Sidebar) */
    [data-testid="stSidebar"] {
        background-color: #ffffff;
        border-right: 1px solid #dfe6e9;
    }

    /* T√≠tulos */
    h1, h2, h3 {
        font-family: 'Roboto', sans-serif !important;
        color: #2d3436 !important;
        font-weight: 700 !important;
    }
    
    /* Texto Comum */
    p, label, li, .stMarkdown {
        color: #636e72 !important;
        font-size: 16px;
    }

    /* Bot√µes (Verde M√©dico / Confian√ßa) */
    .stButton > button {
        background-color: #00b894;
        color: white !important;
        border: none;
        border-radius: 30px; /* Bot√µes redondos */
        padding: 0.6rem 1.2rem;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 6px rgba(0, 184, 148, 0.2);
        width: 100%;
    }

    .stButton > button:hover {
        background-color: #00a884;
        transform: translateY(-2px);
        box-shadow: 0 6px 12px rgba(0, 184, 148, 0.3);
    }

    /* Inputs de Chat */
    .stChatInput textarea {
        background-color: #ffffff !important;
        border: 1px solid #b2bec3 !important;
        border-radius: 20px;
        color: #2d3436 !important;
    }
    .stChatInput textarea:focus {
        border-color: #00b894 !important;
        box-shadow: 0 0 5px rgba(0, 184, 148, 0.5) !important;
    }

    /* Mensagens do Chat */
    [data-testid="stChatMessage"] {
        background-color: #ffffff;
        border: 1px solid #dfe6e9;
        border-radius: 15px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.05);
    }
    
    /* Destaque para a IA (Avatar) */
    [data-testid="stChatMessage"] [data-testid="stImage"] {
        background-color: #e3fdfd;
        border: 2px solid #00b894;
    }

    /* Expander (Protocolos) */
    .streamlit-expanderHeader {
        background-color: #ffffff;
        border: 1px solid #00b894;
        border-radius: 8px;
        color: #00b894 !important;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# 3. Credenciais (API Key)
api_key = st.secrets.get("GROQ_API_KEY") or os.environ.get("GROQ_API_KEY")
if not api_key:
    # Fallback para teste local se necess√°rio, mas ideal √© usar st.secrets
    # Coloque sua chave aqui se rodar localmente e n√£o tiver configurado secrets
    api_key =  

os.environ["GROQ_API_KEY"] = api_key

# 4. Engenharia de Prompt (Cora√ß√£o do Sistema)
PROMPT_PROFISSIONAL = (
    "ATUE COMO: Especialista Cl√≠nico Multidisciplinar S√™nior (M√©dico/Enfermeiro/Psic√≥logo).\n"
    "CONTEXTO: An√°lise de prontu√°rios, exames e literatura m√©dica.\n"
    "DIRETRIZES:\n"
    "1. Use terminologia t√©cnica precisa (CID-10, DSM-5, Farmacologia).\n"
    "2. Cite refer√™ncias exatas do texto fornecido.\n"
    "3. Seja objetivo, focado em conduta cl√≠nica, diagn√≥stico diferencial e protocolos.\n"
    "4. Mantenha tom acad√™mico e formal.\n"
    "---------------------\n"
    "DOCUMENTOS CL√çNICOS: {context_str}\n"
    "---------------------\n"
    "SOLICITA√á√ÉO DO PROFISSIONAL: {query_str}\n"
    "PARECER T√âCNICO:"
)

PROMPT_PACIENTE = (
    "ATUE COMO: Um Profissional de Sa√∫de Emp√°tico e Did√°tico.\n"
    "MISS√ÉO: Traduzir 'mediqu√™s' para linguagem simples e acolhedora.\n"
    "DIRETRIZES:\n"
    "1. Explique termos complexos com analogias simples.\n"
    "2. Foque no cuidado, bem-estar e instru√ß√µes claras.\n"
    "3. Seja tranquilizador, mas realista baseando-se nos documentos.\n"
    "4. NUNCA fa√ßa diagn√≥sticos definitivos sem ressaltar a necessidade de consulta presencial.\n"
    "---------------------\n"
    "INFORMA√á√ïES DE SA√öDE: {context_str}\n"
    "---------------------\n"
    "D√öVIDA DO PACIENTE: {query_str}\n"
    "RESPOSTA ACOLHEDORA:"
)

# 5. Carregar Modelos
@st.cache_resource
def carregar_cerebro():
    Settings.llm = Groq(model="llama-3.3-70b-versatile")
    Settings.embed_model = HuggingFaceEmbedding(
        model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    )
    return True

with st.spinner("Esterilizando ambiente e carregando m√≥dulos de IA..."):
    carregar_cerebro()

# 6. Sidebar (Triagem)
with st.sidebar:
    st.markdown("### üè• TRIAGEM")
    st.info("Sistema de Apoio √† Decis√£o Cl√≠nica")
    
    perfil = st.radio(
        "QUEM EST√Å ACESSANDO?",
        ["PROFISSIONAL DE SA√öDE", "PACIENTE / FAMILIAR"],
        index=0
    )
    
    st.markdown("---")
    st.markdown("### üìÅ PRONTU√ÅRIO / EXAMES")
    uploaded_files = st.file_uploader("Fa√ßa upload de PDFs ou TXT", accept_multiple_files=True)
    
    processar = st.button("üîç ANALISAR DADOS CL√çNICOS")
    
    if st.button("üßπ NOVA CONSULTA"):
        st.session_state.messages = []
        st.rerun()

# 7. Processamento (RAG)
if "query_engine" not in st.session_state:
    st.session_state.query_engine = None

if uploaded_files and processar:
    with st.spinner("Analisando par√¢metros fisiol√≥gicos e texto..."):
        try:
            with tempfile.TemporaryDirectory() as temp_dir:
                for uploaded_file in uploaded_files:
                    path = os.path.join(temp_dir, uploaded_file.name)
                    with open(path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                
                documents = SimpleDirectoryReader(temp_dir).load_data()
                index = VectorStoreIndex.from_documents(documents)
                
                st.session_state.index_base = index
                st.session_state.documents_loaded = True
                logger.info(f"TRIAGEM: {len(uploaded_files)} documentos m√©dicos processados.")
                
            st.success("‚úÖ Prontu√°rio Digital Indexado.")
        except Exception as e:
            st.error("Erro na leitura dos exames.")
            logger.error(f"ERRO CL√çNICO: {e}")

# 8. Interface Principal
st.title("MediSync AI")
st.markdown("##### ASSISTENTE DE SA√öDE INTEGRADA")

# √Årea de Ajuda (Expander)
with st.expander("üìã PROTOCOLO DE USO (LEIA COM ATEN√á√ÉO)"):
    st.markdown("""
    **Este sistema utiliza IA Avan√ßada para leitura de documentos de sa√∫de.**
    
    1. **Profissionais (M√©dicos, Enfermagem, Psicologia, Fono, etc):**
       - Receber√£o an√°lises t√©cnicas, sugest√µes de conduta baseadas em evid√™ncias e correla√ß√µes cl√≠nicas.
    2. **Pacientes:**
       - Receber√£o explica√ß√µes did√°ticas sobre laudos, bulas e orienta√ß√µes de cuidado.
    
    *‚ö†Ô∏è Importante: Esta ferramenta √© um suporte. Jamais substitui o julgamento cl√≠nico ou consulta presencial.*
    """)

# Chat
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("Digite a queixa cl√≠nica ou d√∫vida..."):
    
    if not st.session_state.get("documents_loaded"):
        st.warning("‚ö†Ô∏è POR FAVOR: Anexe os documentos cl√≠nicos na barra lateral primeiro.")
        st.stop()

    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    logger.info(f"CONSULTA [{perfil}]: {prompt}")

    with st.chat_message("assistant"):
        with st.spinner("Gerando parecer cl√≠nico..."):
            try:
                if perfil == "PROFISSIONAL DE SA√öDE":
                    template = PromptTemplate(PROMPT_PROFISSIONAL)
                else:
                    template = PromptTemplate(PROMPT_PACIENTE)
                
                query_engine = st.session_state.index_base.as_query_engine(
                    text_qa_template=template,
                    similarity_top_k=5
                )
                
                response = query_engine.query(prompt)
                st.markdown(str(response))
                st.session_state.messages.append({"role": "assistant", "content": str(response)})
                logger.info("PARECER FINALIZADO.")
                
            except Exception as e:
                st.error("Erro ao processar solicita√ß√£o.")
                logger.error(f"FALHA NA RESPOSTA: {e}")
